{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Section 5.3: Build List of Lookup Timestamps from our Large Crawls**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parse the timestamps of the `HS_DESC` lookups collected during our large-scale crawl in section 4.2. Restrict this set of lookups to the ones with the optimal injection rate of 3 subresources per second.\n",
    "- Write all (start, end) timestamp tuples into `hsdesc_lookup_details.json`.\n",
    "- We use this large list of actual lookup timestamps to \"replay\" lookups in our attack simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from os.path import abspath, dirname, join, basename, isfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIND: Set this path to the file system location of a crawl conducted\n",
    "#       with our instrumentation code and subsequent execution of\n",
    "#       `../4_attack-tuning/process_events_log.py` on the crawl folders.\n",
    "#       The data set we provide in this repository for section 4.2 does\n",
    "#       not contain the required `lookup_timestamps` key in `results.json`.\n",
    "\n",
    "# DATA_DIR = abspath(\"PLEASE SET TO APPROPRIATE TOR CRAWL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_PARAMS_JSON = \"experiment.json\"\n",
    "HSDESC_EVENTS_CSV = \"events_hs_desc.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_json(json_path):\n",
    "    return json.loads(open(json_path).read())\n",
    "\n",
    "\n",
    "def load_from_csv(csv_path):\n",
    "    data = []\n",
    "\n",
    "    with open(csv_path, \"r\", newline=\"\") as csv_fp:\n",
    "\n",
    "        reader = csv.DictReader(csv_fp)\n",
    "\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dt(time_str):\n",
    "    \"\"\"Convert from format used in HSDESC_EVENTS_CSV to datetime.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        return datetime.strptime(time_str, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    except:\n",
    "        # Timestamp lacks the ms portion when ms = .000\n",
    "        return datetime.strptime(time_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "def find_earliest_circ_start(hsdesc_events):\n",
    "    \"\"\"Find the earliest circ start time.\n",
    "    All lookup timestamps will be relative to this.\"\"\"\n",
    "\n",
    "    return min([convert_to_dt(hsdesc_event['start']) for hsdesc_event in hsdesc_events])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsdesc_lookup_details = []\n",
    "n_experiments = 0\n",
    "lookup_durations = []\n",
    "\n",
    "for result_json in tqdm(glob(join(DATA_DIR, \"*MAX_HSDESC_RATE*_3.0*_COMPLETED/results.json\"))):\n",
    "\n",
    "    exp_dir = dirname(result_json)\n",
    "    exp_params = load_from_json(join(exp_dir, EXPERIMENT_PARAMS_JSON))\n",
    "\n",
    "    n_experiments += 1\n",
    "    lookup_times_dict = {}\n",
    "    lookup_times = []\n",
    "    \n",
    "    results = load_from_json(result_json)\n",
    "    \n",
    "    lookup_times_dict[\"guard_fp\"] = exp_params[\"guard_fp\"]\n",
    "    \n",
    "    # We don't use exp_start_time in the simulations.\n",
    "    # Just for redundancy and to help with debugging.\n",
    "    lookup_times_dict[\"exp_start_time\"] = exp_params[\"start_time\"]\n",
    "\n",
    "    hsdesc_events = load_from_csv(join(exp_dir, HSDESC_EVENTS_CSV))\n",
    "    \n",
    "    # Get the first circuit's start time.\n",
    "    # All timestamps will be relative to that.\n",
    "    min_dt = find_earliest_circ_start(hsdesc_events)\n",
    "    attack_start_ts = min_dt.timestamp()\n",
    "    \n",
    "    lookup_times_dict[\"attack_start_time\"] = attack_start_ts\n",
    "    lookup_times_dict[\"lookup_times\"] = sorted(results['lookup_timestamps'], key=lambda x: x[0])\n",
    "    \n",
    "    hsdesc_lookup_details.append(lookup_times_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hsdesc_lookup_details.json\", \"w\") as f:\n",
    "    json.dump(hsdesc_lookup_details, f)\n",
    "    f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
